#######################
#–£–°–¢–ê–ù–û–í–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô
#######################

!pip install -q openai gradio tiktoken langchain langchain-openai langchain-community chromadb

#######################
# –ò–ú–ü–û–†–¢–´
#######################

import os
import shutil
import ast
import json
import logging
import pandas as pd
import gradio as gr
import tiktoken
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from io import StringIO

#Google Colab
from google.colab import auth, drive, files
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

#LangChain
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.schema import Document

#######################
# –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø
#######################

class LogHandler:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –ª–æ–≥–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ"""

    def __init__(self):
        self.logs = []
        self.setup_logging()

    def setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[logging.StreamHandler()]
        )
        self.logger = logging.getLogger(__name__)

    def log(self, message: str, level: str = "INFO"):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ª–æ–≥–∞"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {level}: {message}"
        self.logs.append(log_entry)

        if level == "ERROR":
            self.logger.error(message)
        elif level == "WARNING":
            self.logger.warning(message)
        else:
            self.logger.info(message)

    def get_logs(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –ª–æ–≥–æ–≤"""
        return "\n".join(self.logs[-50:])  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 50 –∑–∞–ø–∏—Å–µ–π

    def clear_logs(self):
        """–û—á–∏—Å—Ç–∫–∞ –ª–æ–≥–æ–≤"""
        self.logs.clear()

#######################
# –ú–û–î–£–õ–¨ –†–ê–ë–û–¢–´ –° GOOGLE COLAB API
#######################

class ColabNotebookManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–æ—É—Ç–±—É–∫–∞–º–∏ Google Colab"""

    def __init__(self, log_handler: LogHandler):
        self.log_handler = log_handler
        self.service = None
        self.user_email = None

    def authenticate(self) -> bool:
        """–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –≤ Google API"""
        try:
            self.log_handler.log("–ù–∞—á–∞–ª–æ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ Google API")
            auth.authenticate_user()
            self.service = build('drive', 'v3')

            # –ü–æ–ª—É—á–∞–µ–º email –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            about = self.service.about().get(fields='user').execute()
            self.user_email = about['user']['emailAddress']

            self.log_handler.log(f"–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {self.user_email}")
            return True

        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏: {str(e)}", "ERROR")
            return False

    def get_notebooks(self) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –Ω–æ—É—Ç–±—É–∫–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            self.log_handler.log("–ü–æ–∏—Å–∫ –Ω–æ—É—Ç–±—É–∫–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")

            query = "(mimeType='application/vnd.google.colaboratory' or mimeType='application/x-ipynb+json')"
            results = self.service.files().list(
                q=query,
                fields="files(id, name, webViewLink, owners)"
            ).execute()

            notebooks = []
            for file in results.get('files', []):
                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è untitled –∏ –Ω–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—â–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
                if 'untitled' in file['name'].lower():
                    continue

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–ª–∞–¥–µ–ª—å—Ü–∞
                is_owner = any(
                    owner.get('emailAddress') == self.user_email
                    for owner in file.get('owners', [])
                )

                if is_owner:
                    notebooks.append({
                        'id': file['id'],
                        'name': file['name'],
                        'link': file['webViewLink']
                    })

            self.log_handler.log(f"–ù–∞–π–¥–µ–Ω–æ {len(notebooks)} –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –Ω–æ—É—Ç–±—É–∫–æ–≤")
            return notebooks

        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ—É—Ç–±—É–∫–æ–≤: {str(e)}", "ERROR")
            return []


    def get_notebook_content(self, notebook_id: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON"""
        try:
            self.log_handler.log(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞ {notebook_id}")

            file_metadata = self.service.files().get(fileId=notebook_id, fields='mimeType').execute()
            mime_type = file_metadata.get('mimeType')

            if mime_type == 'application/vnd.google.colaboratory':
                # –ü–æ–ø—ã—Ç–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ Colab —Ñ–∞–π–ª–∞
                try:
                    content = self.service.files().export(
                        fileId=notebook_id,
                        mimeType='application/x-ipynb+json'
                    ).execute()
                    return json.loads(content.decode('utf-8'))
                except HttpError as export_error:
                    if export_error.resp.status == 403:
                        # –ï—Å–ª–∏ —ç–∫—Å–ø–æ—Ä—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—ã—Ç–∞–µ–º—Å—è —Å–∫–∞—á–∞—Ç—å –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ñ–∞–π–ª
                        self.log_handler.log(f"–≠–∫—Å–ø–æ—Ä—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è {notebook_id}, –ø—ã—Ç–∞–µ–º—Å—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–±", "WARNING")
                        try:
                            content = self.service.files().get_media(fileId=notebook_id).execute()
                            return json.loads(content.decode('utf-8'))
                        except:
                            # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - —Å–æ–∑–¥–∞—Ç—å –∫–æ–ø–∏—é –∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –µ—ë
                            self.log_handler.log(f"–°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ø–∏—é —Ñ–∞–π–ª–∞ {notebook_id}", "INFO")
                            copy_metadata = {'name': f'temp_copy_{notebook_id}'}
                            copied_file = self.service.files().copy(
                                fileId=notebook_id,
                                body=copy_metadata
                            ).execute()

                            try:
                                content = self.service.files().export(
                                    fileId=copied_file['id'],
                                    mimeType='application/x-ipynb+json'
                                ).execute()

                                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ø–∏—é
                                self.service.files().delete(fileId=copied_file['id']).execute()

                                return json.loads(content.decode('utf-8'))
                            except:
                                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ø–∏—é –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
                                self.service.files().delete(fileId=copied_file['id']).execute()
                                raise
                    else:
                        raise export_error
            else:
                # –î–ª—è –æ–±—ã—á–Ω—ã—Ö .ipynb —Ñ–∞–π–ª–æ–≤
                content = self.service.files().get_media(fileId=notebook_id).execute()
                return json.loads(content.decode('utf-8'))

        except HttpError as e:
            if e.resp.status == 403:
                self.log_handler.log(f"–ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –Ω–æ—É—Ç–±—É–∫—É {notebook_id}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º", "WARNING")
            else:
                self.log_handler.log(f"HTTP –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–æ—É—Ç–±—É–∫–∞ {notebook_id}: {str(e)}", "ERROR")
            return None
        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–æ—É—Ç–±—É–∫–∞ {notebook_id}: {str(e)}", "ERROR")
            return None


#######################
# –ú–û–î–£–õ–¨ –ê–ù–ê–õ–ò–ó–ê –ö–û–î–ê
#######################

class CodeAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–æ–¥–∞ Python"""

    def __init__(self, log_handler: LogHandler):
        self.log_handler = log_handler

    def extract_imports(self, code: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤ –∏–∑ –∫–æ–¥–∞"""
        try:
            tree = ast.parse(code)
            imports = []

            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        imports.append(alias.name)
                elif isinstance(node, ast.ImportFrom):
                    module = node.module or ''
                    for alias in node.names:
                        imports.append(f"{module}.{alias.name}" if module else alias.name)

            return list(set(imports))

        except SyntaxError:
            return []
        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–º–ø–æ—Ä—Ç–æ–≤: {str(e)}", "WARNING")
            return []

    def extract_functions_and_classes(self, code: str) -> Dict[str, List[Dict]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–π –∏ –∫–ª–∞—Å—Å–æ–≤ –∏–∑ –∫–æ–¥–∞"""
        try:
            tree = ast.parse(code)
            functions = []
            classes = []

            # –°–Ω–∞—á–∞–ª–∞ –Ω–∞–π–¥–µ–º –≤—Å–µ –∫–ª–∞—Å—Å—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏
            class_nodes = [node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]

            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ –≤–Ω—É—Ç—Ä–∏ –∫–ª–∞—Å—Å–∞
                    is_inside_class = False
                    for class_node in class_nodes:
                        if node in class_node.body:
                            is_inside_class = True
                            break

                    if not is_inside_class:
                        try:
                            functions.append({
                                'name': node.name,
                                'code': ast.unparse(node) if hasattr(ast, 'unparse') else f"def {node.name}(...): ...",
                                'type': 'function'
                            })
                        except:
                            functions.append({
                                'name': node.name,
                                'code': f"def {node.name}(...): ...",
                                'type': 'function'
                            })

                elif isinstance(node, ast.ClassDef):
                    methods = []
                    for item in node.body:
                        if isinstance(item, ast.FunctionDef):
                            try:
                                methods.append({
                                    'name': item.name,
                                    'code': ast.unparse(item) if hasattr(ast, 'unparse') else f"def {item.name}(...): ...",
                                    'type': 'method'
                                })
                            except:
                                methods.append({
                                    'name': item.name,
                                    'code': f"def {item.name}(...): ...",
                                    'type': 'method'
                                })

                    try:
                        class_code = ast.unparse(node) if hasattr(ast, 'unparse') else f"class {node.name}: ..."
                    except:
                        class_code = f"class {node.name}: ..."

                    classes.append({
                        'name': node.name,
                        'code': class_code,
                        'methods': methods,
                        'type': 'class'
                    })

            return {'functions': functions, 'classes': classes}

        except SyntaxError:
            return {'functions': [], 'classes': []}
        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ—É–Ω–∫—Ü–∏–π –∏ –∫–ª–∞—Å—Å–æ–≤: {str(e)}", "WARNING")
            return {'functions': [], 'classes': []}

#######################
# –ú–û–î–£–õ–¨ –û–ë–†–ê–ë–û–¢–ö–ò –ù–û–£–¢–ë–£–ö–û–í
#######################

class NotebookProcessor:
    """–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ—É—Ç–±—É–∫–æ–≤"""

    def __init__(self, log_handler: LogHandler):
        self.log_handler = log_handler
        self.code_analyzer = CodeAnalyzer(log_handler)

    def extract_headers(self, cells: List[Dict]) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏–∑ —è—á–µ–µ–∫ markdown"""
        headers = []

        for cell in cells:
            if cell.get('cell_type') == 'markdown':
                source = ''.join(cell.get('source', []))
                lines = source.split('\n')

                for line in lines:
                    line = line.strip()
                    if line.startswith('#'):
                        # –û—á–∏—Å—Ç–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
                        header = line.lstrip('#').strip()
                        if header:
                            headers.append(header)

        return headers

    def extract_conclusion(self, cells: List[Dict]) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ '–ò—Ç–æ–≥'"""
        conclusion_found = False
        conclusion_text = []

        for cell in cells:
            if cell.get('cell_type') == 'markdown':
                source = ''.join(cell.get('source', []))
                lines = source.split('\n')

                for line in lines:
                    line_clean = line.strip().lower()
                    if line_clean.startswith('#') and '–∏—Ç–æ–≥' in line_clean:
                        conclusion_found = True
                        continue

                    if conclusion_found:
                        if line.strip().startswith('#'):
                            # –ù–æ–≤—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ - –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º —Å–±–æ—Ä
                            break
                        conclusion_text.append(line)

        result = '\n'.join(conclusion_text).strip()
        return result if result else "–ù–µ—Ç –∏—Ç–æ–≥–∞"

    def extract_code_elements(self, cells: List[Dict]) -> Tuple[List[str], Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤, —Ñ—É–Ω–∫—Ü–∏–π –∏ –∫–ª–∞—Å—Å–æ–≤ –∏–∑ –∫–æ–¥–∞"""
        all_imports = []
        all_code_elements = {'functions': [], 'classes': []}

        for cell in cells:
            if cell.get('cell_type') == 'code':
                source = ''.join(cell.get('source', []))

                # –û—á–∏—Å—Ç–∫–∞ –æ—Ç –º–∞–≥–∏—á–µ—Å–∫–∏—Ö –∫–æ–º–∞–Ω–¥
                lines = source.split('\n')
                clean_lines = []
                for line in lines:
                    if not line.strip().startswith(('!', '%', '?')):
                        clean_lines.append(line)

                clean_code = '\n'.join(clean_lines)

                if clean_code.strip():
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤
                    imports = self.code_analyzer.extract_imports(clean_code)
                    all_imports.extend(imports)

                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–π –∏ –∫–ª–∞—Å—Å–æ–≤
                    code_elements = self.code_analyzer.extract_functions_and_classes(clean_code)
                    all_code_elements['functions'].extend(code_elements['functions'])
                    all_code_elements['classes'].extend(code_elements['classes'])

        return list(set(all_imports)), all_code_elements

    def process_notebook(self, notebook_data: Dict, notebook_info: Dict) -> Dict:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞"""
        try:
            self.log_handler.log(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ—É—Ç–±—É–∫–∞: {notebook_info['name']}")

            cells = notebook_data.get('cells', [])

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            headers = self.extract_headers(cells)
            conclusion = self.extract_conclusion(cells)
            imports, code_elements = self.extract_code_elements(cells)

            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ñ—É–Ω–∫—Ü–∏–π –∏ –∫–ª–∞—Å—Å–æ–≤
            functions_and_classes = []
            for func in code_elements['functions']:
                functions_and_classes.append(f"–§—É–Ω–∫—Ü–∏—è: {func['name']}")
            for cls in code_elements['classes']:
                functions_and_classes.append(f"–ö–ª–∞—Å—Å: {cls['name']}")

            result = {
                '—Å—Å—ã–ª–∫–∞': notebook_info['link'],
                '–Ω–∞–∑–≤–∞–Ω–∏–µ': notebook_info['name'],
                '–∑–∞–≥–æ–ª–æ–≤–∫–∏': '; '.join(headers) if headers else '–Ω–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤',
                '–±–∏–±–ª–∏–æ—Ç–µ–∫–∏': ', '.join(imports) if imports else '–Ω–µ—Ç –∏–º–ø–æ—Ä—Ç–æ–≤',
                '–∫–ª–∞—Å—Å—ã –∏ —Ñ—É–Ω–∫—Ü–∏–∏': '; '.join(functions_and_classes) if functions_and_classes else '–Ω–µ—Ç —Ñ—É–Ω–∫—Ü–∏–π',
                '–æ–ø–∏—Å–∞–Ω–∏–µ': '',  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ LLM
                '–∏—Ç–æ–≥': conclusion,
                'code_elements': code_elements  # –î–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ LLM
            }

            self.log_handler.log(f"–ù–æ—É—Ç–±—É–∫ {notebook_info['name']} –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            return result

        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ—É—Ç–±—É–∫–∞ {notebook_info['name']}: {str(e)}", "ERROR")
            return None

#######################
# –ú–û–î–£–õ–¨ –†–ê–ë–û–¢–´ –° LLM
#######################

class LLMProcessor:
    """–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª—å—é"""

    def __init__(self, api_key: str, endpoint: str, log_handler: LogHandler):
        self.log_handler = log_handler
        self.llm = ChatOpenAI(
            openai_api_key=api_key,
            openai_api_base=endpoint,
            temperature=0.3,
            model_name="gpt-4.1-nano"
        )
        self.encoding = tiktoken.get_encoding("cl100k_base")

    def count_tokens(self, text: str) -> int:
        """–ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ"""
        return len(self.encoding.encode(text))

    def describe_code_element(self, element: Dict) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è —ç–ª–µ–º–µ–Ω—Ç–∞ –∫–æ–¥–∞ –æ—Ç LLM"""
        try:
            element_type = element.get('type', 'function')
            element_name = element.get('name', 'unknown')
            element_code = element.get('code', '')

            prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–¥ {element_type} '{element_name}' –∏ –æ–ø–∏—à–∏ –µ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:

{element_name}
–õ–æ–≥–∏—á–µ—Å–∫–∞—è –∑–∞–¥–∞—á–∞
–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–ø–æ—Å–æ–±–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏

–ö–æ–¥:
python
{element_code}

–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏ –∫—Ä–∞—Ç–∫–∏–º.
"""

            response = self.llm.invoke(prompt)
            self.log_handler.log(f"–ü–æ–ª—É—á–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è {element_type} {element_name}")

            return response.content.strip()

        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –æ—Ç LLM: {str(e)}", "ERROR")
            return f"–û—à–∏–±–∫–∞ –æ–ø–∏—Å–∞–Ω–∏—è {element.get('name', 'unknown')}"

    def describe_class_with_methods(self, class_element: Dict) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞ —Å –º–µ—Ç–æ–¥–∞–º–∏"""
        try:
            class_name = class_element.get('name', 'unknown')
            methods = class_element.get('methods', [])

            # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤
            method_descriptions = []
            for method in methods:
                method_desc = self.describe_code_element(method)
                method_descriptions.append(method_desc)

            # –ó–∞—Ç–µ–º –æ–ø–∏—Å—ã–≤–∞–µ–º –≤–µ—Å—å –∫–ª–∞—Å—Å
            methods_summary = '\n'.join([f"- {method['name']}" for method in methods])

            prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–ª–∞—Å—Å '{class_name}' —Å –º–µ—Ç–æ–¥–∞–º–∏ –∏ –æ–ø–∏—à–∏ –µ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:

{class_name}
–õ–æ–≥–∏—á–µ—Å–∫–∞—è –∑–∞–¥–∞—á–∞
–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–ø–æ—Å–æ–±–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏

–ú–µ—Ç–æ–¥—ã –∫–ª–∞—Å—Å–∞:
{methods_summary}

–û–ø–∏—Å–∞–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤:
{chr(10).join(method_descriptions)}

–î–∞–π –æ–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –∏ –µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è.
"""

            response = self.llm.invoke(prompt)
            self.log_handler.log(f"–ü–æ–ª—É—á–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –∫–ª–∞—Å—Å–∞ {class_name}")

            return response.content.strip()

        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞ –æ—Ç LLM: {str(e)}", "ERROR")
            return f"–û—à–∏–±–∫–∞ –æ–ø–∏—Å–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞ {class_element.get('name', 'unknown')}"

    def process_notebook_descriptions(self, notebook_data: Dict) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∫–æ–¥–∞ –≤ –Ω–æ—É—Ç–±—É–∫–µ"""
        try:
            code_elements = notebook_data.get('code_elements', {'functions': [], 'classes': []})
            descriptions = []

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ—É–Ω–∫—Ü–∏–π
            for function in code_elements['functions']:
                desc = self.describe_code_element(function)
                descriptions.append(desc)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∞—Å—Å–æ–≤
            for class_element in code_elements['classes']:
                desc = self.describe_class_with_methods(class_element)
                descriptions.append(desc)

            return '\n\n'.join(descriptions) if descriptions else '–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–π'

        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–ø–∏—Å–∞–Ω–∏–π: {str(e)}", "ERROR")
            return '–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–ø–∏—Å–∞–Ω–∏–π'

#######################
# –ú–û–î–£–õ–¨ –†–ê–ë–û–¢–´ –° –í–ï–ö–¢–û–†–ù–û–ô –ë–ê–ó–û–ô
#######################

class ChromaManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–æ–π Chroma"""

    def __init__(self, api_key: str, endpoint: str, log_handler: LogHandler):
        self.log_handler = log_handler

        # –ò–ó–ú–ï–ù–ï–ù–û: –¥–æ–±–∞–≤–ª–µ–Ω endpoint –¥–ª—è embeddings
        self.embeddings = OpenAIEmbeddings(
            openai_api_key=api_key,
            openai_api_base=endpoint,
            model="text-embedding-3-small"  # –ò–ó–ú–ï–ù–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º text-embedding-3-small
        )

        self.vectorstore = None
        self.qa_chain = None
        self.api_key = api_key
        self.endpoint = endpoint

        # –ò–ó–ú–ï–ù–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º cl100k_base —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
        self.encoding = tiktoken.get_encoding("cl100k_base")

    def create_vectorstore(self, df: pd.DataFrame) -> bool:
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –∏–∑ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞"""
        try:
            self.log_handler.log("–°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã Chroma")

            documents = []
            metadatas = []

            for _, row in df.iterrows():
                # –î–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è Chroma (—Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ)
                doc_content = f"""
–ù–∞–∑–≤–∞–Ω–∏–µ: {row['–Ω–∞–∑–≤–∞–Ω–∏–µ']}
–ó–∞–≥–æ–ª–æ–≤–∫–∏: {row['–∑–∞–≥–æ–ª–æ–≤–∫–∏']}
–û–ø–∏—Å–∞–Ω–∏–µ: {row['–æ–ø–∏—Å–∞–Ω–∏–µ']}
–ò—Ç–æ–≥: {row['–∏—Ç–æ–≥']}
"""

                # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è Chroma
                metadata = {
                    '—Å—Å—ã–ª–∫–∞': row['—Å—Å—ã–ª–∫–∞'],
                    '–±–∏–±–ª–∏–æ—Ç–µ–∫–∏': row['–±–∏–±–ª–∏–æ—Ç–µ–∫–∏'],
                    '–∫–ª–∞—Å—Å—ã –∏ —Ñ—É–Ω–∫—Ü–∏–∏': row['–∫–ª–∞—Å—Å—ã –∏ —Ñ—É–Ω–∫—Ü–∏–∏']
                }

                documents.append(Document(page_content=doc_content, metadata=metadata))

            # –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã
            self.vectorstore = Chroma.from_documents(
                documents=documents,
                embedding=self.embeddings,
                persist_directory="./chroma_db"
            )

            # –ò—Å–æ–∑–¥–∞–Ω–∏–µ QA —Ü–µ–ø–æ—á–∫–∏ —Å ChatOpenAI
            self.qa_chain = RetrievalQA.from_chain_type(
                llm=ChatOpenAI(
                    openai_api_key=self.api_key,
                    openai_api_base=self.endpoint,
                    temperature=0.3,
                    model_name="gpt-4.1-nano"
                ),
                chain_type="stuff",
                retriever=self.vectorstore.as_retriever(search_kwargs={"k": 3}),
                return_source_documents=True
            )

            self.log_handler.log(f"–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ —Å–æ–∑–¥–∞–Ω–∞ —Å {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏")
            return True

        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã: {str(e)}", "ERROR")
            return False

    def query(self, question: str) -> Tuple[str, int, List[str]]:
        """–ó–∞–ø—Ä–æ—Å –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ"""
        try:
            if not self.qa_chain:
                return "–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –Ω–µ —Å–æ–∑–¥–∞–Ω–∞", 0, []

            self.log_handler.log(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {question}")

            # –ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ
            input_tokens = len(self.encoding.encode(question))

            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
            result = self.qa_chain({"query": question})

            # –ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
            output_tokens = len(self.encoding.encode(result['result']))
            total_tokens = input_tokens + output_tokens

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            links = []
            for doc in result.get('source_documents', []):
                link = doc.metadata.get('—Å—Å—ã–ª–∫–∞')
                if link and link not in links:
                    links.append(link)

            self.log_handler.log(f"–ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {total_tokens}")

            return result['result'], total_tokens, links

        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}", "ERROR")
            return f"–û—à–∏–±–∫–∞: {str(e)}", 0, []

#######################
# –ì–õ–ê–í–ù–´–ô –ö–õ–ê–°–° –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø
#######################

class NotebookAssistant:
    """–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ—É—Ç–±—É–∫–æ–≤"""

    def __init__(self):
        self.log_handler = LogHandler()
        self.colab_manager = ColabNotebookManager(self.log_handler)
        self.notebook_processor = NotebookProcessor(self.log_handler)
        self.llm_processor = None
        self.chroma_manager = None
        self.df = None
        self.api_key = None
        self.endpoint = None

    def set_api_key(self, api_key: str, endpoint: str) -> str:
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ API –∫–ª—é—á–∞ –∏ endpoint OpenAI"""
        try:
            self.api_key = api_key
            self.endpoint = endpoint
            self.llm_processor = LLMProcessor(api_key, endpoint, self.log_handler)
            self.chroma_manager = ChromaManager(api_key, endpoint, self.log_handler)
            self.log_handler.log("API –∫–ª—é—á –∏ endpoint —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
            return "API –∫–ª—é—á –∏ endpoint —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ"
        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ API –∫–ª—é—á–∞: {str(e)}", "ERROR")
            return f"–û—à–∏–±–∫–∞: {str(e)}"

    def get_data(self) -> Tuple[str, str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –Ω–æ—É—Ç–±—É–∫–æ–≤"""
        try:
            if not self.api_key:
                return "–°–Ω–∞—á–∞–ª–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ API –∫–ª—é—á OpenAI", self.log_handler.get_logs()

            self.log_handler.clear_logs()
            self.log_handler.log("–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ—É—Ç–±—É–∫–æ–≤")

            # –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
            if not self.colab_manager.authenticate():
                return "–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏", self.log_handler.get_logs()

            # –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ—É—Ç–±—É–∫–æ–≤
            notebooks = self.colab_manager.get_notebooks()
            if not notebooks:
                return "–ü–æ–¥—Ö–æ–¥—è—â–∏–µ –Ω–æ—É—Ç–±—É–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã", self.log_handler.get_logs()

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ—É—Ç–±—É–∫–æ–≤
            processed_data = []
            for notebook in notebooks:
                self.log_handler.log(f"–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ—É—Ç–±—É–∫–∞: {notebook['name']}")

                notebook_content = self.colab_manager.get_notebook_content(notebook['id'])
                if notebook_content:
                    processed_notebook = self.notebook_processor.process_notebook(
                        notebook_content, notebook
                    )

                    if processed_notebook:
                        # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏–π –æ—Ç LLM
                        self.log_handler.log(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏–π –æ—Ç LLM –¥–ª—è: {notebook['name']}")
                        description = self.llm_processor.process_notebook_descriptions(processed_notebook)
                        processed_notebook['–æ–ø–∏—Å–∞–Ω–∏–µ'] = description

                        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                        del processed_notebook['code_elements']
                        processed_data.append(processed_notebook)

            # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞
            self.df = pd.DataFrame(processed_data)

            self.log_handler.log(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –°–æ–∑–¥–∞–Ω –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —Å {len(self.df)} –∑–∞–ø–∏—Å—è–º–∏")

            return f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(self.df)} –Ω–æ—É—Ç–±—É–∫–æ–≤", self.log_handler.get_logs()

        except Exception as e:
            self.log_handler.log(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}", "ERROR")
            return f"–û—à–∏–±–∫–∞: {str(e)}", self.log_handler.get_logs()

    def download_dataframe(self) -> Tuple[str, Optional[str]]:
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞"""
        try:
            if self.df is None:
                return "–°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ", None

            filename = f"notebooks_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            filepath = f"/content/{filename}"
            self.df.to_csv(filepath, index=False, encoding='utf-8')

            self.log_handler.log(f"–î–∞—Ç–∞—Ñ—Ä–µ–π–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")
            return f"–§–∞–π–ª {filename} –≥–æ—Ç–æ–≤ –∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—é", filepath

        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {str(e)}", "ERROR")
            return f"–û—à–∏–±–∫–∞: {str(e)}", None

    def load_dataframe(self, file_path: str) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            if not file_path:
                return "–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω"

            self.df = pd.read_csv(file_path, encoding='utf-8')
            self.log_handler.log(f"–î–∞—Ç–∞—Ñ—Ä–µ–π–º –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ {file_path}")
            return f"–î–∞—Ç–∞—Ñ—Ä–µ–π–º –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ. –ó–∞–ø–∏—Å–µ–π: {len(self.df)}"

        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞: {str(e)}", "ERROR")
            return f"–û—à–∏–±–∫–∞: {str(e)}"

    def save_vectorstore(self) -> str:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã"""
        try:
            if not self.chroma_manager or not self.chroma_manager.vectorstore:
                return "–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –Ω–µ —Å–æ–∑–¥–∞–Ω–∞"

            # Chroma –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ persist_directory
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_dir = f"/content/chroma_backup_{timestamp}"

            import shutil
            shutil.copytree("./chroma_db", backup_dir)

            self.log_handler.log(f"–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {backup_dir}")
            return f"–ë–∞–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {backup_dir}"

        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±–∞–∑—ã: {str(e)}", "ERROR")
            return f"–û—à–∏–±–∫–∞: {str(e)}"

    def load_vectorstore(self, backup_dir: str) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã"""
        try:
            if not backup_dir:
                return "–ü–∞–ø–∫–∞ –Ω–µ –≤—ã–±—Ä–∞–Ω–∞"

            if not self.chroma_manager:
                return "–°–Ω–∞—á–∞–ª–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ API –∫–ª—é—á"

            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –±–∞–∑—É –µ—Å–ª–∏ –µ—Å—Ç—å
            if os.path.exists("./chroma_db"):
                shutil.rmtree("./chroma_db")

            # –ö–æ–ø–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—É—é –±–∞–∑—É
            shutil.copytree(backup_dir, "./chroma_db")

            # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É
            self.chroma_manager.vectorstore = Chroma(
                persist_directory="./chroma_db",
                embedding_function=self.chroma_manager.embeddings
            )

            # –°–æ–∑–¥–∞–Ω–∏–µ QA —Ü–µ–ø–æ—á–∫–∏
            from langchain_openai import ChatOpenAI
            self.chroma_manager.qa_chain = RetrievalQA.from_chain_type(
                llm=ChatOpenAI(
                    openai_api_key=self.chroma_manager.api_key,
                    openai_api_base=self.chroma_manager.endpoint,
                    temperature=0.3,
                    model_name="gpt-4.1-nano"
                ),
                chain_type="stuff",
                retriever=self.chroma_manager.vectorstore.as_retriever(search_kwargs={"k": 3}),
                return_source_documents=True
            )

            self.log_handler.log(f"–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {backup_dir}")
            return "–ë–∞–∑–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ"

        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã: {str(e)}", "ERROR")
            return f"–û—à–∏–±–∫–∞: {str(e)}"


    def create_vectorstore(self) -> Tuple[str, str]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã"""
        try:
            if self.df is None:
                return "–°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ", self.log_handler.get_logs()

            if not self.chroma_manager:
                return "API –∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω", self.log_handler.get_logs()

            success = self.chroma_manager.create_vectorstore(self.df)

            if success:
                return "–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ", self.log_handler.get_logs()
            else:
                return "–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã", self.log_handler.get_logs()

        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±–∞–∑—ã: {str(e)}", "ERROR")
            return f"–û—à–∏–±–∫–∞: {str(e)}", self.log_handler.get_logs()

    def query_assistant(self, question: str) -> Tuple[str, str, str]:
        """–ó–∞–ø—Ä–æ—Å –∫ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É"""
        try:
            if not self.chroma_manager or not self.chroma_manager.qa_chain:
                return "–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –Ω–µ —Å–æ–∑–¥–∞–Ω–∞", "", self.log_handler.get_logs()

            answer, tokens, links = self.chroma_manager.query(question)

            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
            response = f"{answer}\n\n"
            if links:
                response += "–°—Å—ã–ª–∫–∏ –Ω–∞ –Ω–æ—É—Ç–±—É–∫–∏:\n"
                for i, link in enumerate(links, 1):
                    response += f"{i}. {link}\n"

            token_info = f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {tokens}"

            return response, token_info, self.log_handler.get_logs()

        except Exception as e:
            self.log_handler.log(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}", "ERROR")
            return f"–û—à–∏–±–∫–∞: {str(e)}", "", self.log_handler.get_logs()

#######################
# –ò–ù–¢–ï–†–§–ï–ô–° GRADIO
#######################

def create_interface():
    """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ Gradio"""

    assistant = NotebookAssistant()

    with gr.Blocks(title="–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ—É—Ç–±—É–∫–æ–≤") as interface:
        gr.Markdown("# ü§ñ –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ—É—Ç–±—É–∫–æ–≤ Google Colab")
        gr.Markdown("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–∞—à–∏ –Ω–æ—É—Ç–±—É–∫–∏ –∏ —Å–æ–∑–¥–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–ª—è –ø–æ–∏—Å–∫–∞")

        with gr.Tab("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞"):
            api_key_input = gr.Textbox(
                label="OpenAI API Key",
                type="password",
                placeholder="sk-..."
            )
            endpoint_input = gr.Textbox(
                label="OpenAI Endpoint",
                placeholder="https://api.openai.com/v1",
                value="https://api.openai.com/v1"
            )
            api_key_btn = gr.Button("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")
            api_key_output = gr.Textbox(label="–°—Ç–∞—Ç—É—Å", interactive=False)

            api_key_btn.click(
                assistant.set_api_key,
                inputs=[api_key_input, endpoint_input],
                outputs=[api_key_output]
            )

        with gr.Tab("üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"):
            with gr.Row():
                get_data_btn = gr.Button("–ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ", variant="primary")
                create_db_btn = gr.Button("–°–æ–∑–¥–∞—Ç—å –±–∞–∑—É", variant="secondary")

            with gr.Row():
                with gr.Column():
                    gr.Markdown("### –î–∞—Ç–∞—Ñ—Ä–µ–π–º")
                    download_btn = gr.Button("–°–∫–∞—á–∞—Ç—å –¥–∞—Ç–∞—Ñ—Ä–µ–π–º")
                    download_file = gr.File(label="–°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª", visible=False)
                    upload_df = gr.File(label="–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Ñ—Ä–µ–π–º (.csv)", file_types=[".csv"])
                    load_df_btn = gr.Button("–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Ñ—Ä–µ–π–º")

                with gr.Column():
                    gr.Markdown("### –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞")
                    save_db_btn = gr.Button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –±–∞–∑—É")
                    upload_db = gr.File(label="–ó–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑—É (–ø–∞–ø–∫–∞)", file_count="directory")
                    load_db_btn = gr.Button("–ó–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑—É")

            status_output = gr.Textbox(label="–°—Ç–∞—Ç—É—Å –æ–ø–µ—Ä–∞—Ü–∏–∏", interactive=False)
            logs_output = gr.Textbox(
                label="–õ–æ–≥–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è",
                lines=10,
                interactive=False
            )

            # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–±—ã—Ç–∏–π
            get_data_btn.click(
                assistant.get_data,
                outputs=[status_output, logs_output]
            )

            def handle_download(assistant_ref):
                status, filepath = assistant_ref.download_dataframe()
                if filepath:
                    return status, gr.update(value=filepath, visible=True)
                return status, gr.update(visible=False)

            download_btn.click(
                lambda: handle_download(assistant),
                outputs=[status_output, download_file]
            )

            load_df_btn.click(
                lambda file: assistant.load_dataframe(file.name if file else ""),
                inputs=[upload_df],
                outputs=[status_output]
            )

            create_db_btn.click(
                assistant.create_vectorstore,
                outputs=[status_output, logs_output]
            )

            save_db_btn.click(
                assistant.save_vectorstore,
                outputs=[status_output]
            )

            load_db_btn.click(
                lambda file: assistant.load_vectorstore(file.name if file else ""),
                inputs=[upload_db],
                outputs=[status_output]
            )


        with gr.Tab("üîç –ü–æ–∏—Å–∫"):
            question_input = gr.Textbox(
                label="–í–∞—à –≤–æ–ø—Ä–æ—Å",
                placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –ù–∞–π–¥–∏ –Ω–æ—É—Ç–±—É–∫–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥–∞–Ω–Ω—ã—Ö",
                lines=2
            )
            search_btn = gr.Button("–ù–∞–π—Ç–∏", variant="primary")

            answer_output = gr.Textbox(
                label="–û—Ç–≤–µ—Ç",
                lines=10,
                interactive=False
            )
            tokens_output = gr.Textbox(label="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤", interactive=False)
            search_logs_output = gr.Textbox(
                label="–õ–æ–≥–∏ –ø–æ–∏—Å–∫–∞",
                lines=5,
                interactive=False
            )

            search_btn.click(
                assistant.query_assistant,
                inputs=[question_input],
                outputs=[answer_output, tokens_output, search_logs_output]
            )

    return interface

#######################
# –ó–ê–ü–£–°–ö –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø
#######################

if __name__ == "__main__":
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    interface = create_interface()
    interface.launch(
        share=True,
        debug=True,
        server_name="0.0.0.0",
        server_port=7860
    )
