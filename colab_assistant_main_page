{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYTbse5YZw4m"
      },
      "outputs": [],
      "source": [
        "#–£–°–¢–ê–ù–û–í–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô\n",
        "\n",
        "!pip install -q openai gradio tiktoken langchain langchain-openai langchain-community chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFgURbe_cI6i"
      },
      "outputs": [],
      "source": [
        "# –ò–ú–ü–û–†–¢–´\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import ast\n",
        "import json\n",
        "import logging\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import tiktoken\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "from datetime import datetime\n",
        "from io import StringIO\n",
        "\n",
        "#Google Colab\n",
        "from google.colab import auth, drive, files\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "\n",
        "#LangChain\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.schema import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dIt9YL2ESf8d"
      },
      "outputs": [],
      "source": [
        "# –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø\n",
        "\n",
        "class LogHandler:\n",
        "    \"\"\"–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –ª–æ–≥–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.logs = []\n",
        "        self.setup_logging()\n",
        "\n",
        "    def setup_logging(self):\n",
        "        \"\"\"–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\"\"\"\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "            handlers=[logging.StreamHandler()]\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def log(self, message: str, level: str = \"INFO\"):\n",
        "        \"\"\"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ª–æ–≥–∞\"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
        "        log_entry = f\"[{timestamp}] {level}: {message}\"\n",
        "        self.logs.append(log_entry)\n",
        "\n",
        "        if level == \"ERROR\":\n",
        "            self.logger.error(message)\n",
        "        elif level == \"WARNING\":\n",
        "            self.logger.warning(message)\n",
        "        else:\n",
        "            self.logger.info(message)\n",
        "\n",
        "    def get_logs(self) -> str:\n",
        "        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –ª–æ–≥–æ–≤\"\"\"\n",
        "        return \"\\n\".join(self.logs[-50:])  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 50 –∑–∞–ø–∏—Å–µ–π\n",
        "\n",
        "    def clear_logs(self):\n",
        "        \"\"\"–û—á–∏—Å—Ç–∫–∞ –ª–æ–≥–æ–≤\"\"\"\n",
        "        self.logs.clear()\n",
        "\n",
        "# –ú–û–î–£–õ–¨ –†–ê–ë–û–¢–´ –° GOOGLE COLAB API\n",
        "\n",
        "class ColabNotebookManager:\n",
        "    \"\"\"–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–æ—É—Ç–±—É–∫–∞–º–∏ Google Colab\"\"\"\n",
        "\n",
        "    def __init__(self, log_handler: LogHandler):\n",
        "        self.log_handler = log_handler\n",
        "        self.service = None\n",
        "        self.user_email = None\n",
        "\n",
        "    def authenticate(self) -> bool:\n",
        "        \"\"\"–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –≤ Google API\"\"\"\n",
        "        try:\n",
        "            self.log_handler.log(\"–ù–∞—á–∞–ª–æ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ Google API\")\n",
        "            auth.authenticate_user()\n",
        "            self.service = build('drive', 'v3')\n",
        "\n",
        "            # –ü–æ–ª—É—á–∞–µ–º email –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
        "            about = self.service.about().get(fields='user').execute()\n",
        "            self.user_email = about['user']['emailAddress']\n",
        "\n",
        "            self.log_handler.log(f\"–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {self.user_email}\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏: {str(e)}\", \"ERROR\")\n",
        "            return False\n",
        "\n",
        "    def get_notebooks(self) -> List[Dict[str, Any]]:\n",
        "        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –Ω–æ—É—Ç–±—É–∫–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\"\"\"\n",
        "        try:\n",
        "            self.log_handler.log(\"–ü–æ–∏—Å–∫ –Ω–æ—É—Ç–±—É–∫–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\")\n",
        "\n",
        "            query = \"(mimeType='application/vnd.google.colaboratory' or mimeType='application/x-ipynb+json')\"\n",
        "            results = self.service.files().list(\n",
        "                q=query,\n",
        "                fields=\"files(id, name, webViewLink, owners)\"\n",
        "            ).execute()\n",
        "\n",
        "            notebooks = []\n",
        "            for file in results.get('files', []):\n",
        "                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è untitled –∏ –Ω–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—â–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é\n",
        "                if 'untitled' in file['name'].lower():\n",
        "                    continue\n",
        "\n",
        "                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–ª–∞–¥–µ–ª—å—Ü–∞\n",
        "                is_owner = any(\n",
        "                    owner.get('emailAddress') == self.user_email\n",
        "                    for owner in file.get('owners', [])\n",
        "                )\n",
        "\n",
        "                if is_owner:\n",
        "                    notebooks.append({\n",
        "                        'id': file['id'],\n",
        "                        'name': file['name'],\n",
        "                        'link': file['webViewLink']\n",
        "                    })\n",
        "\n",
        "            self.log_handler.log(f\"–ù–∞–π–¥–µ–Ω–æ {len(notebooks)} –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –Ω–æ—É—Ç–±—É–∫–æ–≤\")\n",
        "            return notebooks\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ—É—Ç–±—É–∫–æ–≤: {str(e)}\", \"ERROR\")\n",
        "            return []\n",
        "\n",
        "\n",
        "    def get_notebook_content(self, notebook_id: str) -> Optional[Dict]:\n",
        "        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON\"\"\"\n",
        "        try:\n",
        "            self.log_handler.log(f\"–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞ {notebook_id}\")\n",
        "\n",
        "            file_metadata = self.service.files().get(fileId=notebook_id, fields='mimeType').execute()\n",
        "            mime_type = file_metadata.get('mimeType')\n",
        "\n",
        "            if mime_type == 'application/vnd.google.colaboratory':\n",
        "                # –ü–æ–ø—ã—Ç–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ Colab —Ñ–∞–π–ª–∞\n",
        "                try:\n",
        "                    content = self.service.files().export(\n",
        "                        fileId=notebook_id,\n",
        "                        mimeType='application/x-ipynb+json'\n",
        "                    ).execute()\n",
        "                    return json.loads(content.decode('utf-8'))\n",
        "                except HttpError as export_error:\n",
        "                    if export_error.resp.status == 403:\n",
        "                        # –ï—Å–ª–∏ —ç–∫—Å–ø–æ—Ä—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—ã—Ç–∞–µ–º—Å—è —Å–∫–∞—á–∞—Ç—å –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ñ–∞–π–ª\n",
        "                        self.log_handler.log(f\"–≠–∫—Å–ø–æ—Ä—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è {notebook_id}, –ø—ã—Ç–∞–µ–º—Å—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–±\", \"WARNING\")\n",
        "                        try:\n",
        "                            content = self.service.files().get_media(fileId=notebook_id).execute()\n",
        "                            return json.loads(content.decode('utf-8'))\n",
        "                        except:\n",
        "                            # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - —Å–æ–∑–¥–∞—Ç—å –∫–æ–ø–∏—é –∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –µ—ë\n",
        "                            self.log_handler.log(f\"–°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ø–∏—é —Ñ–∞–π–ª–∞ {notebook_id}\", \"INFO\")\n",
        "                            copy_metadata = {'name': f'temp_copy_{notebook_id}'}\n",
        "                            copied_file = self.service.files().copy(\n",
        "                                fileId=notebook_id,\n",
        "                                body=copy_metadata\n",
        "                            ).execute()\n",
        "\n",
        "                            try:\n",
        "                                content = self.service.files().export(\n",
        "                                    fileId=copied_file['id'],\n",
        "                                    mimeType='application/x-ipynb+json'\n",
        "                                ).execute()\n",
        "\n",
        "                                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ø–∏—é\n",
        "                                self.service.files().delete(fileId=copied_file['id']).execute()\n",
        "\n",
        "                                return json.loads(content.decode('utf-8'))\n",
        "                            except:\n",
        "                                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ø–∏—é –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏\n",
        "                                self.service.files().delete(fileId=copied_file['id']).execute()\n",
        "                                raise\n",
        "                    else:\n",
        "                        raise export_error\n",
        "            else:\n",
        "                # –î–ª—è –æ–±—ã—á–Ω—ã—Ö .ipynb —Ñ–∞–π–ª–æ–≤\n",
        "                content = self.service.files().get_media(fileId=notebook_id).execute()\n",
        "                return json.loads(content.decode('utf-8'))\n",
        "\n",
        "        except HttpError as e:\n",
        "            if e.resp.status == 403:\n",
        "                self.log_handler.log(f\"–ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –Ω–æ—É—Ç–±—É–∫—É {notebook_id}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º\", \"WARNING\")\n",
        "            else:\n",
        "                self.log_handler.log(f\"HTTP –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–æ—É—Ç–±—É–∫–∞ {notebook_id}: {str(e)}\", \"ERROR\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–æ—É—Ç–±—É–∫–∞ {notebook_id}: {str(e)}\", \"ERROR\")\n",
        "            return None\n",
        "\n",
        "# –ú–û–î–£–õ–¨ –ê–ù–ê–õ–ò–ó–ê –ö–û–î–ê\n",
        "\n",
        "class CodeAnalyzer:\n",
        "    \"\"\"–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–æ–¥–∞ Python\"\"\"\n",
        "\n",
        "    def __init__(self, log_handler: LogHandler):\n",
        "        self.log_handler = log_handler\n",
        "\n",
        "    def extract_imports(self, code: str) -> List[str]:\n",
        "        \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤ –∏–∑ –∫–æ–¥–∞\"\"\"\n",
        "        try:\n",
        "            tree = ast.parse(code)\n",
        "            imports = []\n",
        "\n",
        "            for node in ast.walk(tree):\n",
        "                if isinstance(node, ast.Import):\n",
        "                    for alias in node.names:\n",
        "                        imports.append(alias.name)\n",
        "                elif isinstance(node, ast.ImportFrom):\n",
        "                    module = node.module or ''\n",
        "                    for alias in node.names:\n",
        "                        imports.append(f\"{module}.{alias.name}\" if module else alias.name)\n",
        "\n",
        "            return list(set(imports))\n",
        "\n",
        "        except SyntaxError:\n",
        "            return []\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–º–ø–æ—Ä—Ç–æ–≤: {str(e)}\", \"WARNING\")\n",
        "            return []\n",
        "\n",
        "    def extract_functions_and_classes(self, code: str) -> Dict[str, List[Dict]]:\n",
        "        \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–π –∏ –∫–ª–∞—Å—Å–æ–≤ –∏–∑ –∫–æ–¥–∞\"\"\"\n",
        "        try:\n",
        "            tree = ast.parse(code)\n",
        "            functions = []\n",
        "            classes = []\n",
        "\n",
        "            # –°–Ω–∞—á–∞–ª–∞ –Ω–∞–π–¥–µ–º –≤—Å–µ –∫–ª–∞—Å—Å—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏\n",
        "            class_nodes = [node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]\n",
        "\n",
        "            for node in ast.walk(tree):\n",
        "                if isinstance(node, ast.FunctionDef):\n",
        "                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ –≤–Ω—É—Ç—Ä–∏ –∫–ª–∞—Å—Å–∞\n",
        "                    is_inside_class = False\n",
        "                    for class_node in class_nodes:\n",
        "                        if node in class_node.body:\n",
        "                            is_inside_class = True\n",
        "                            break\n",
        "\n",
        "                    if not is_inside_class:\n",
        "                        try:\n",
        "                            functions.append({\n",
        "                                'name': node.name,\n",
        "                                'code': ast.unparse(node) if hasattr(ast, 'unparse') else f\"def {node.name}(...): ...\",\n",
        "                                'type': 'function'\n",
        "                            })\n",
        "                        except:\n",
        "                            functions.append({\n",
        "                                'name': node.name,\n",
        "                                'code': f\"def {node.name}(...): ...\",\n",
        "                                'type': 'function'\n",
        "                            })\n",
        "\n",
        "                elif isinstance(node, ast.ClassDef):\n",
        "                    methods = []\n",
        "                    for item in node.body:\n",
        "                        if isinstance(item, ast.FunctionDef):\n",
        "                            try:\n",
        "                                methods.append({\n",
        "                                    'name': item.name,\n",
        "                                    'code': ast.unparse(item) if hasattr(ast, 'unparse') else f\"def {item.name}(...): ...\",\n",
        "                                    'type': 'method'\n",
        "                                })\n",
        "                            except:\n",
        "                                methods.append({\n",
        "                                    'name': item.name,\n",
        "                                    'code': f\"def {item.name}(...): ...\",\n",
        "                                    'type': 'method'\n",
        "                                })\n",
        "\n",
        "                    try:\n",
        "                        class_code = ast.unparse(node) if hasattr(ast, 'unparse') else f\"class {node.name}: ...\"\n",
        "                    except:\n",
        "                        class_code = f\"class {node.name}: ...\"\n",
        "\n",
        "                    classes.append({\n",
        "                        'name': node.name,\n",
        "                        'code': class_code,\n",
        "                        'methods': methods,\n",
        "                        'type': 'class'\n",
        "                    })\n",
        "\n",
        "            return {'functions': functions, 'classes': classes}\n",
        "\n",
        "        except SyntaxError:\n",
        "            return {'functions': [], 'classes': []}\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ—É–Ω–∫—Ü–∏–π –∏ –∫–ª–∞—Å—Å–æ–≤: {str(e)}\", \"WARNING\")\n",
        "            return {'functions': [], 'classes': []}\n",
        "\n",
        "# –ú–û–î–£–õ–¨ –û–ë–†–ê–ë–û–¢–ö–ò –ù–û–£–¢–ë–£–ö–û–í\n",
        "\n",
        "class NotebookProcessor:\n",
        "    \"\"\"–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ—É—Ç–±—É–∫–æ–≤\"\"\"\n",
        "\n",
        "    def __init__(self, log_handler: LogHandler):\n",
        "        self.log_handler = log_handler\n",
        "        self.code_analyzer = CodeAnalyzer(log_handler)\n",
        "\n",
        "    def extract_headers(self, cells: List[Dict]) -> List[str]:\n",
        "        \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏–∑ —è—á–µ–µ–∫ markdown\"\"\"\n",
        "        headers = []\n",
        "\n",
        "        for cell in cells:\n",
        "            if cell.get('cell_type') == 'markdown':\n",
        "                source = ''.join(cell.get('source', []))\n",
        "                lines = source.split('\\n')\n",
        "\n",
        "                for line in lines:\n",
        "                    line = line.strip()\n",
        "                    if line.startswith('#'):\n",
        "                        # –û—á–∏—Å—Ç–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤\n",
        "                        header = line.lstrip('#').strip()\n",
        "                        if header:\n",
        "                            headers.append(header)\n",
        "\n",
        "        return headers\n",
        "\n",
        "    def extract_conclusion(self, cells: List[Dict]) -> str:\n",
        "        \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ '–ò—Ç–æ–≥'\"\"\"\n",
        "        conclusion_found = False\n",
        "        conclusion_text = []\n",
        "\n",
        "        for cell in cells:\n",
        "            if cell.get('cell_type') == 'markdown':\n",
        "                source = ''.join(cell.get('source', []))\n",
        "                lines = source.split('\\n')\n",
        "\n",
        "                for line in lines:\n",
        "                    line_clean = line.strip().lower()\n",
        "                    if line_clean.startswith('#') and '–∏—Ç–æ–≥' in line_clean:\n",
        "                        conclusion_found = True\n",
        "                        continue\n",
        "\n",
        "                    if conclusion_found:\n",
        "                        if line.strip().startswith('#'):\n",
        "                            # –ù–æ–≤—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ - –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º —Å–±–æ—Ä\n",
        "                            break\n",
        "                        conclusion_text.append(line)\n",
        "\n",
        "        result = '\\n'.join(conclusion_text).strip()\n",
        "        return result if result else \"–ù–µ—Ç –∏—Ç–æ–≥–∞\"\n",
        "\n",
        "    def extract_code_elements(self, cells: List[Dict]) -> Tuple[List[str], Dict]:\n",
        "        \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤, —Ñ—É–Ω–∫—Ü–∏–π –∏ –∫–ª–∞—Å—Å–æ–≤ –∏–∑ –∫–æ–¥–∞\"\"\"\n",
        "        all_imports = []\n",
        "        all_code_elements = {'functions': [], 'classes': []}\n",
        "\n",
        "        for cell in cells:\n",
        "            if cell.get('cell_type') == 'code':\n",
        "                source = ''.join(cell.get('source', []))\n",
        "\n",
        "                # –û—á–∏—Å—Ç–∫–∞ –æ—Ç –º–∞–≥–∏—á–µ—Å–∫–∏—Ö –∫–æ–º–∞–Ω–¥\n",
        "                lines = source.split('\\n')\n",
        "                clean_lines = []\n",
        "                for line in lines:\n",
        "                    if not line.strip().startswith(('!', '%', '?')):\n",
        "                        clean_lines.append(line)\n",
        "\n",
        "                clean_code = '\\n'.join(clean_lines)\n",
        "\n",
        "                if clean_code.strip():\n",
        "                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤\n",
        "                    imports = self.code_analyzer.extract_imports(clean_code)\n",
        "                    all_imports.extend(imports)\n",
        "\n",
        "                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–π –∏ –∫–ª–∞—Å—Å–æ–≤\n",
        "                    code_elements = self.code_analyzer.extract_functions_and_classes(clean_code)\n",
        "                    all_code_elements['functions'].extend(code_elements['functions'])\n",
        "                    all_code_elements['classes'].extend(code_elements['classes'])\n",
        "\n",
        "        return list(set(all_imports)), all_code_elements\n",
        "\n",
        "    def process_notebook(self, notebook_data: Dict, notebook_info: Dict) -> Dict:\n",
        "        \"\"\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞\"\"\"\n",
        "        try:\n",
        "            self.log_handler.log(f\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ—É—Ç–±—É–∫–∞: {notebook_info['name']}\")\n",
        "\n",
        "            cells = notebook_data.get('cells', [])\n",
        "\n",
        "            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
        "            headers = self.extract_headers(cells)\n",
        "            conclusion = self.extract_conclusion(cells)\n",
        "            imports, code_elements = self.extract_code_elements(cells)\n",
        "\n",
        "            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ñ—É–Ω–∫—Ü–∏–π –∏ –∫–ª–∞—Å—Å–æ–≤\n",
        "            functions_and_classes = []\n",
        "            for func in code_elements['functions']:\n",
        "                functions_and_classes.append(f\"–§—É–Ω–∫—Ü–∏—è: {func['name']}\")\n",
        "            for cls in code_elements['classes']:\n",
        "                functions_and_classes.append(f\"–ö–ª–∞—Å—Å: {cls['name']}\")\n",
        "\n",
        "            result = {\n",
        "                '—Å—Å—ã–ª–∫–∞': notebook_info['link'],\n",
        "                '–Ω–∞–∑–≤–∞–Ω–∏–µ': notebook_info['name'],\n",
        "                '–∑–∞–≥–æ–ª–æ–≤–∫–∏': '; '.join(headers) if headers else '–Ω–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤',\n",
        "                '–±–∏–±–ª–∏–æ—Ç–µ–∫–∏': ', '.join(imports) if imports else '–Ω–µ—Ç –∏–º–ø–æ—Ä—Ç–æ–≤',\n",
        "                '–∫–ª–∞—Å—Å—ã –∏ —Ñ—É–Ω–∫—Ü–∏–∏': '; '.join(functions_and_classes) if functions_and_classes else '–Ω–µ—Ç —Ñ—É–Ω–∫—Ü–∏–π',\n",
        "                '–æ–ø–∏—Å–∞–Ω–∏–µ': '',  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ LLM\n",
        "                '–∏—Ç–æ–≥': conclusion,\n",
        "                'code_elements': code_elements  # –î–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ LLM\n",
        "            }\n",
        "\n",
        "            self.log_handler.log(f\"–ù–æ—É—Ç–±—É–∫ {notebook_info['name']} –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ—É—Ç–±—É–∫–∞ {notebook_info['name']}: {str(e)}\", \"ERROR\")\n",
        "            return None\n",
        "\n",
        "# –ú–û–î–£–õ–¨ –†–ê–ë–û–¢–´ –° LLM\n",
        "\n",
        "class LLMProcessor:\n",
        "    \"\"\"–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª—å—é\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str, endpoint: str, log_handler: LogHandler):\n",
        "        self.log_handler = log_handler\n",
        "        self.llm = ChatOpenAI(\n",
        "            openai_api_key=api_key,\n",
        "            openai_api_base=endpoint,\n",
        "            temperature=0.3,\n",
        "            model_name=\"gpt-4.1-nano\"\n",
        "        )\n",
        "        self.encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "    def count_tokens(self, text: str) -> int:\n",
        "        \"\"\"–ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ\"\"\"\n",
        "        return len(self.encoding.encode(text))\n",
        "\n",
        "    def describe_code_element(self, element: Dict) -> str:\n",
        "        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è —ç–ª–µ–º–µ–Ω—Ç–∞ –∫–æ–¥–∞ –æ—Ç LLM\"\"\"\n",
        "        try:\n",
        "            element_type = element.get('type', 'function')\n",
        "            element_name = element.get('name', 'unknown')\n",
        "            element_code = element.get('code', '')\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–¥ {element_type} '{element_name}' –∏ –æ–ø–∏—à–∏ –µ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n",
        "\n",
        "{element_name}\n",
        "–õ–æ–≥–∏—á–µ—Å–∫–∞—è –∑–∞–¥–∞—á–∞\n",
        "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–ø–æ—Å–æ–±–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏\n",
        "\n",
        "–ö–æ–¥:\n",
        "python\n",
        "{element_code}\n",
        "\n",
        "–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏ –∫—Ä–∞—Ç–∫–∏–º.\n",
        "\"\"\"\n",
        "\n",
        "            response = self.llm.invoke(prompt)\n",
        "            self.log_handler.log(f\"–ü–æ–ª—É—á–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è {element_type} {element_name}\")\n",
        "\n",
        "            return response.content.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –æ—Ç LLM: {str(e)}\", \"ERROR\")\n",
        "            return f\"–û—à–∏–±–∫–∞ –æ–ø–∏—Å–∞–Ω–∏—è {element.get('name', 'unknown')}\"\n",
        "\n",
        "    def describe_class_with_methods(self, class_element: Dict) -> str:\n",
        "        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞ —Å –º–µ—Ç–æ–¥–∞–º–∏\"\"\"\n",
        "        try:\n",
        "            class_name = class_element.get('name', 'unknown')\n",
        "            methods = class_element.get('methods', [])\n",
        "\n",
        "            # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤\n",
        "            method_descriptions = []\n",
        "            for method in methods:\n",
        "                method_desc = self.describe_code_element(method)\n",
        "                method_descriptions.append(method_desc)\n",
        "\n",
        "            # –ó–∞—Ç–µ–º –æ–ø–∏—Å—ã–≤–∞–µ–º –≤–µ—Å—å –∫–ª–∞—Å—Å\n",
        "            methods_summary = '\\n'.join([f\"- {method['name']}\" for method in methods])\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–ª–∞—Å—Å '{class_name}' —Å –º–µ—Ç–æ–¥–∞–º–∏ –∏ –æ–ø–∏—à–∏ –µ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n",
        "\n",
        "{class_name}\n",
        "–õ–æ–≥–∏—á–µ—Å–∫–∞—è –∑–∞–¥–∞—á–∞\n",
        "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–ø–æ—Å–æ–±–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏\n",
        "\n",
        "–ú–µ—Ç–æ–¥—ã –∫–ª–∞—Å—Å–∞:\n",
        "{methods_summary}\n",
        "\n",
        "–û–ø–∏—Å–∞–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤:\n",
        "{chr(10).join(method_descriptions)}\n",
        "\n",
        "–î–∞–π –æ–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –∏ –µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è.\n",
        "\"\"\"\n",
        "\n",
        "            response = self.llm.invoke(prompt)\n",
        "            self.log_handler.log(f\"–ü–æ–ª—É—á–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –∫–ª–∞—Å—Å–∞ {class_name}\")\n",
        "\n",
        "            return response.content.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞ –æ—Ç LLM: {str(e)}\", \"ERROR\")\n",
        "            return f\"–û—à–∏–±–∫–∞ –æ–ø–∏—Å–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞ {class_element.get('name', 'unknown')}\"\n",
        "\n",
        "    def process_notebook_descriptions(self, notebook_data: Dict) -> str:\n",
        "        \"\"\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∫–æ–¥–∞ –≤ –Ω–æ—É—Ç–±—É–∫–µ\"\"\"\n",
        "        try:\n",
        "            code_elements = notebook_data.get('code_elements', {'functions': [], 'classes': []})\n",
        "            descriptions = []\n",
        "\n",
        "            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ—É–Ω–∫—Ü–∏–π\n",
        "            for function in code_elements['functions']:\n",
        "                desc = self.describe_code_element(function)\n",
        "                descriptions.append(desc)\n",
        "\n",
        "            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∞—Å—Å–æ–≤\n",
        "            for class_element in code_elements['classes']:\n",
        "                desc = self.describe_class_with_methods(class_element)\n",
        "                descriptions.append(desc)\n",
        "\n",
        "            return '\\n\\n'.join(descriptions) if descriptions else '–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–π'\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–ø–∏—Å–∞–Ω–∏–π: {str(e)}\", \"ERROR\")\n",
        "            return '–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–ø–∏—Å–∞–Ω–∏–π'\n",
        "\n",
        "# –ú–û–î–£–õ–¨ –†–ê–ë–û–¢–´ –° –í–ï–ö–¢–û–†–ù–û–ô –ë–ê–ó–û–ô\n",
        "\n",
        "class ChromaManager:\n",
        "    \"\"\"–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–æ–π Chroma\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str, endpoint: str, log_handler: LogHandler):\n",
        "        self.log_handler = log_handler\n",
        "\n",
        "        # –ò–ó–ú–ï–ù–ï–ù–û: –¥–æ–±–∞–≤–ª–µ–Ω endpoint –¥–ª—è embeddings\n",
        "        self.embeddings = OpenAIEmbeddings(\n",
        "            openai_api_key=api_key,\n",
        "            openai_api_base=endpoint,\n",
        "            model=\"text-embedding-3-small\"  # –ò–ó–ú–ï–ù–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º text-embedding-3-small\n",
        "        )\n",
        "\n",
        "        self.vectorstore = None\n",
        "        self.qa_chain = None\n",
        "        self.api_key = api_key\n",
        "        self.endpoint = endpoint\n",
        "\n",
        "        # –ò–ó–ú–ï–ù–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º cl100k_base —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä\n",
        "        self.encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "    def create_vectorstore(self, df: pd.DataFrame) -> bool:\n",
        "        \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –∏–∑ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞\"\"\"\n",
        "        try:\n",
        "            self.log_handler.log(\"–°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã Chroma\")\n",
        "\n",
        "            documents = []\n",
        "            metadatas = []\n",
        "\n",
        "            for _, row in df.iterrows():\n",
        "                # –î–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è Chroma (—Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ)\n",
        "                doc_content = f\"\"\"\n",
        "–ù–∞–∑–≤–∞–Ω–∏–µ: {row['–Ω–∞–∑–≤–∞–Ω–∏–µ']}\n",
        "–ó–∞–≥–æ–ª–æ–≤–∫–∏: {row['–∑–∞–≥–æ–ª–æ–≤–∫–∏']}\n",
        "–û–ø–∏—Å–∞–Ω–∏–µ: {row['–æ–ø–∏—Å–∞–Ω–∏–µ']}\n",
        "–ò—Ç–æ–≥: {row['–∏—Ç–æ–≥']}\n",
        "\"\"\"\n",
        "\n",
        "                # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è Chroma\n",
        "                metadata = {\n",
        "                    '—Å—Å—ã–ª–∫–∞': row['—Å—Å—ã–ª–∫–∞'],\n",
        "                    '–±–∏–±–ª–∏–æ—Ç–µ–∫–∏': row['–±–∏–±–ª–∏–æ—Ç–µ–∫–∏'],\n",
        "                    '–∫–ª–∞—Å—Å—ã –∏ —Ñ—É–Ω–∫—Ü–∏–∏': row['–∫–ª–∞—Å—Å—ã –∏ —Ñ—É–Ω–∫—Ü–∏–∏']\n",
        "                }\n",
        "\n",
        "                documents.append(Document(page_content=doc_content, metadata=metadata))\n",
        "\n",
        "            # –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã\n",
        "            self.vectorstore = Chroma.from_documents(\n",
        "                documents=documents,\n",
        "                embedding=self.embeddings,\n",
        "                persist_directory=\"./chroma_db\"\n",
        "            )\n",
        "\n",
        "            # –ò—Å–æ–∑–¥–∞–Ω–∏–µ QA —Ü–µ–ø–æ—á–∫–∏ —Å ChatOpenAI\n",
        "            self.qa_chain = RetrievalQA.from_chain_type(\n",
        "                llm=ChatOpenAI(\n",
        "                    openai_api_key=self.api_key,\n",
        "                    openai_api_base=self.endpoint,\n",
        "                    temperature=0.3,\n",
        "                    model_name=\"gpt-4.1-nano\"\n",
        "                ),\n",
        "                chain_type=\"stuff\",\n",
        "                retriever=self.vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
        "                return_source_documents=True\n",
        "            )\n",
        "\n",
        "            self.log_handler.log(f\"–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ —Å–æ–∑–¥–∞–Ω–∞ —Å {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã: {str(e)}\", \"ERROR\")\n",
        "            return False\n",
        "\n",
        "    def query(self, question: str) -> Tuple[str, int, List[str]]:\n",
        "        \"\"\"–ó–∞–ø—Ä–æ—Å –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ\"\"\"\n",
        "        try:\n",
        "            if not self.qa_chain:\n",
        "                return \"–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –Ω–µ —Å–æ–∑–¥–∞–Ω–∞\", 0, []\n",
        "\n",
        "            self.log_handler.log(f\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {question}\")\n",
        "\n",
        "            # –ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ\n",
        "            input_tokens = len(self.encoding.encode(question))\n",
        "\n",
        "            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞\n",
        "            result = self.qa_chain({\"query\": question})\n",
        "\n",
        "            # –ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ\n",
        "            output_tokens = len(self.encoding.encode(result['result']))\n",
        "            total_tokens = input_tokens + output_tokens\n",
        "\n",
        "            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\n",
        "            links = []\n",
        "            for doc in result.get('source_documents', []):\n",
        "                link = doc.metadata.get('—Å—Å—ã–ª–∫–∞')\n",
        "                if link and link not in links:\n",
        "                    links.append(link)\n",
        "\n",
        "            self.log_handler.log(f\"–ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {total_tokens}\")\n",
        "\n",
        "            return result['result'], total_tokens, links\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}\", \"ERROR\")\n",
        "            return f\"–û—à–∏–±–∫–∞: {str(e)}\", 0, []\n",
        "\n",
        "# –ì–õ–ê–í–ù–´–ô –ö–õ–ê–°–° –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø\n",
        "\n",
        "class NotebookAssistant:\n",
        "    \"\"\"–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ—É—Ç–±—É–∫–æ–≤\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.log_handler = LogHandler()\n",
        "        self.colab_manager = ColabNotebookManager(self.log_handler)\n",
        "        self.notebook_processor = NotebookProcessor(self.log_handler)\n",
        "        self.llm_processor = None\n",
        "        self.chroma_manager = None\n",
        "        self.df = None\n",
        "        self.api_key = None\n",
        "        self.endpoint = None\n",
        "\n",
        "    def set_api_key(self, api_key: str, endpoint: str) -> str:\n",
        "        \"\"\"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ API –∫–ª—é—á–∞ –∏ endpoint OpenAI\"\"\"\n",
        "        try:\n",
        "            self.api_key = api_key\n",
        "            self.endpoint = endpoint\n",
        "            self.llm_processor = LLMProcessor(api_key, endpoint, self.log_handler)\n",
        "            self.chroma_manager = ChromaManager(api_key, endpoint, self.log_handler)\n",
        "            self.log_handler.log(\"API –∫–ª—é—á –∏ endpoint —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ\")\n",
        "            return \"API –∫–ª—é—á –∏ endpoint —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ\"\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ API –∫–ª—é—á–∞: {str(e)}\", \"ERROR\")\n",
        "            return f\"–û—à–∏–±–∫–∞: {str(e)}\"\n",
        "\n",
        "    def get_data(self) -> Tuple[str, str]:\n",
        "        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –Ω–æ—É—Ç–±—É–∫–æ–≤\"\"\"\n",
        "        try:\n",
        "            if not self.api_key:\n",
        "                return \"–°–Ω–∞—á–∞–ª–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ API –∫–ª—é—á OpenAI\", self.log_handler.get_logs()\n",
        "\n",
        "            self.log_handler.clear_logs()\n",
        "            self.log_handler.log(\"–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ—É—Ç–±—É–∫–æ–≤\")\n",
        "\n",
        "            # –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è\n",
        "            if not self.colab_manager.authenticate():\n",
        "                return \"–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏\", self.log_handler.get_logs()\n",
        "\n",
        "            # –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ—É—Ç–±—É–∫–æ–≤\n",
        "            notebooks = self.colab_manager.get_notebooks()\n",
        "            if not notebooks:\n",
        "                return \"–ü–æ–¥—Ö–æ–¥—è—â–∏–µ –Ω–æ—É—Ç–±—É–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\", self.log_handler.get_logs()\n",
        "\n",
        "            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ—É—Ç–±—É–∫–æ–≤\n",
        "            processed_data = []\n",
        "            for notebook in notebooks:\n",
        "                self.log_handler.log(f\"–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ—É—Ç–±—É–∫–∞: {notebook['name']}\")\n",
        "\n",
        "                notebook_content = self.colab_manager.get_notebook_content(notebook['id'])\n",
        "                if notebook_content:\n",
        "                    processed_notebook = self.notebook_processor.process_notebook(\n",
        "                        notebook_content, notebook\n",
        "                    )\n",
        "\n",
        "                    if processed_notebook:\n",
        "                        # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏–π –æ—Ç LLM\n",
        "                        self.log_handler.log(f\"–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏–π –æ—Ç LLM –¥–ª—è: {notebook['name']}\")\n",
        "                        description = self.llm_processor.process_notebook_descriptions(processed_notebook)\n",
        "                        processed_notebook['–æ–ø–∏—Å–∞–Ω–∏–µ'] = description\n",
        "\n",
        "                        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
        "                        del processed_notebook['code_elements']\n",
        "                        processed_data.append(processed_notebook)\n",
        "\n",
        "            # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞\n",
        "            self.df = pd.DataFrame(processed_data)\n",
        "\n",
        "            self.log_handler.log(f\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –°–æ–∑–¥–∞–Ω –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —Å {len(self.df)} –∑–∞–ø–∏—Å—è–º–∏\")\n",
        "\n",
        "            return f\"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(self.df)} –Ω–æ—É—Ç–±—É–∫–æ–≤\", self.log_handler.get_logs()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}\", \"ERROR\")\n",
        "            return f\"–û—à–∏–±–∫–∞: {str(e)}\", self.log_handler.get_logs()\n",
        "\n",
        "    def download_dataframe(self) -> Tuple[str, Optional[str]]:\n",
        "        \"\"\"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞\"\"\"\n",
        "        try:\n",
        "            if self.df is None:\n",
        "                return \"–°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ\", None\n",
        "\n",
        "            filename = f\"notebooks_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "            filepath = f\"/content/{filename}\"\n",
        "            self.df.to_csv(filepath, index=False, encoding='utf-8')\n",
        "\n",
        "            self.log_handler.log(f\"–î–∞—Ç–∞—Ñ—Ä–µ–π–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}\")\n",
        "            return f\"–§–∞–π–ª {filename} –≥–æ—Ç–æ–≤ –∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—é\", filepath\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {str(e)}\", \"ERROR\")\n",
        "            return f\"–û—à–∏–±–∫–∞: {str(e)}\", None\n",
        "\n",
        "    def load_dataframe(self, file_path: str) -> str:\n",
        "        \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ –∏–∑ —Ñ–∞–π–ª–∞\"\"\"\n",
        "        try:\n",
        "            if not file_path:\n",
        "                return \"–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω\"\n",
        "\n",
        "            self.df = pd.read_csv(file_path, encoding='utf-8')\n",
        "            self.log_handler.log(f\"–î–∞—Ç–∞—Ñ—Ä–µ–π–º –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ {file_path}\")\n",
        "            return f\"–î–∞—Ç–∞—Ñ—Ä–µ–π–º –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ. –ó–∞–ø–∏—Å–µ–π: {len(self.df)}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞: {str(e)}\", \"ERROR\")\n",
        "            return f\"–û—à–∏–±–∫–∞: {str(e)}\"\n",
        "\n",
        "    def save_vectorstore(self) -> str:\n",
        "        \"\"\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã\"\"\"\n",
        "        try:\n",
        "            if not self.chroma_manager or not self.chroma_manager.vectorstore:\n",
        "                return \"–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –Ω–µ —Å–æ–∑–¥–∞–Ω–∞\"\n",
        "\n",
        "            # Chroma –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ persist_directory\n",
        "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            backup_dir = f\"/content/chroma_backup_{timestamp}\"\n",
        "\n",
        "            import shutil\n",
        "            shutil.copytree(\"./chroma_db\", backup_dir)\n",
        "\n",
        "            self.log_handler.log(f\"–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {backup_dir}\")\n",
        "            return f\"–ë–∞–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {backup_dir}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±–∞–∑—ã: {str(e)}\", \"ERROR\")\n",
        "            return f\"–û—à–∏–±–∫–∞: {str(e)}\"\n",
        "\n",
        "    def load_vectorstore(self, backup_dir: str) -> str:\n",
        "        \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã\"\"\"\n",
        "        try:\n",
        "            if not backup_dir:\n",
        "                return \"–ü–∞–ø–∫–∞ –Ω–µ –≤—ã–±—Ä–∞–Ω–∞\"\n",
        "\n",
        "            if not self.chroma_manager:\n",
        "                return \"–°–Ω–∞—á–∞–ª–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ API –∫–ª—é—á\"\n",
        "\n",
        "            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –±–∞–∑—É –µ—Å–ª–∏ –µ—Å—Ç—å\n",
        "            if os.path.exists(\"./chroma_db\"):\n",
        "                shutil.rmtree(\"./chroma_db\")\n",
        "\n",
        "            # –ö–æ–ø–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—É—é –±–∞–∑—É\n",
        "            shutil.copytree(backup_dir, \"./chroma_db\")\n",
        "\n",
        "            # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É\n",
        "            self.chroma_manager.vectorstore = Chroma(\n",
        "                persist_directory=\"./chroma_db\",\n",
        "                embedding_function=self.chroma_manager.embeddings\n",
        "            )\n",
        "\n",
        "            # –°–æ–∑–¥–∞–Ω–∏–µ QA —Ü–µ–ø–æ—á–∫–∏\n",
        "            from langchain_openai import ChatOpenAI\n",
        "            self.chroma_manager.qa_chain = RetrievalQA.from_chain_type(\n",
        "                llm=ChatOpenAI(\n",
        "                    openai_api_key=self.chroma_manager.api_key,\n",
        "                    openai_api_base=self.chroma_manager.endpoint,\n",
        "                    temperature=0.3,\n",
        "                    model_name=\"gpt-4.1-nano\"\n",
        "                ),\n",
        "                chain_type=\"stuff\",\n",
        "                retriever=self.chroma_manager.vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
        "                return_source_documents=True\n",
        "            )\n",
        "\n",
        "            self.log_handler.log(f\"–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {backup_dir}\")\n",
        "            return \"–ë–∞–∑–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã: {str(e)}\", \"ERROR\")\n",
        "            return f\"–û—à–∏–±–∫–∞: {str(e)}\"\n",
        "\n",
        "\n",
        "    def create_vectorstore(self) -> Tuple[str, str]:\n",
        "        \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã\"\"\"\n",
        "        try:\n",
        "            if self.df is None:\n",
        "                return \"–°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ\", self.log_handler.get_logs()\n",
        "\n",
        "            if not self.chroma_manager:\n",
        "                return \"API –∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\", self.log_handler.get_logs()\n",
        "\n",
        "            success = self.chroma_manager.create_vectorstore(self.df)\n",
        "\n",
        "            if success:\n",
        "                return \"–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ\", self.log_handler.get_logs()\n",
        "            else:\n",
        "                return \"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã\", self.log_handler.get_logs()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±–∞–∑—ã: {str(e)}\", \"ERROR\")\n",
        "            return f\"–û—à–∏–±–∫–∞: {str(e)}\", self.log_handler.get_logs()\n",
        "\n",
        "    def query_assistant(self, question: str) -> Tuple[str, str, str]:\n",
        "        \"\"\"–ó–∞–ø—Ä–æ—Å –∫ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É\"\"\"\n",
        "        try:\n",
        "            if not self.chroma_manager or not self.chroma_manager.qa_chain:\n",
        "                return \"–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –Ω–µ —Å–æ–∑–¥–∞–Ω–∞\", \"\", self.log_handler.get_logs()\n",
        "\n",
        "            answer, tokens, links = self.chroma_manager.query(question)\n",
        "\n",
        "            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞\n",
        "            response = f\"{answer}\\n\\n\"\n",
        "            if links:\n",
        "                response += \"–°—Å—ã–ª–∫–∏ –Ω–∞ –Ω–æ—É—Ç–±—É–∫–∏:\\n\"\n",
        "                for i, link in enumerate(links, 1):\n",
        "                    response += f\"{i}. {link}\\n\"\n",
        "\n",
        "            token_info = f\"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {tokens}\"\n",
        "\n",
        "            return response, token_info, self.log_handler.get_logs()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_handler.log(f\"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}\", \"ERROR\")\n",
        "            return f\"–û—à–∏–±–∫–∞: {str(e)}\", \"\", self.log_handler.get_logs()\n",
        "\n",
        "# –ò–ù–¢–ï–†–§–ï–ô–° GRADIO\n",
        "\n",
        "def create_interface():\n",
        "    \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ Gradio\"\"\"\n",
        "\n",
        "    assistant = NotebookAssistant()\n",
        "\n",
        "    with gr.Blocks(title=\"–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ—É—Ç–±—É–∫–æ–≤\") as interface:\n",
        "        gr.Markdown(\"# ü§ñ –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ—É—Ç–±—É–∫–æ–≤ Google Colab\")\n",
        "        gr.Markdown(\"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–∞—à–∏ –Ω–æ—É—Ç–±—É–∫–∏ –∏ —Å–æ–∑–¥–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–ª—è –ø–æ–∏—Å–∫–∞\")\n",
        "\n",
        "        with gr.Tab(\"‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞\"):\n",
        "            api_key_input = gr.Textbox(\n",
        "                label=\"OpenAI API Key\",\n",
        "                type=\"password\",\n",
        "                placeholder=\"sk-...\"\n",
        "            )\n",
        "            endpoint_input = gr.Textbox(\n",
        "                label=\"OpenAI Endpoint\",\n",
        "                placeholder=\"https://api.openai.com/v1\",\n",
        "                value=\"https://api.openai.com/v1\"\n",
        "            )\n",
        "            api_key_btn = gr.Button(\"–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\")\n",
        "            api_key_output = gr.Textbox(label=\"–°—Ç–∞—Ç—É—Å\", interactive=False)\n",
        "\n",
        "            api_key_btn.click(\n",
        "                assistant.set_api_key,\n",
        "                inputs=[api_key_input, endpoint_input],\n",
        "                outputs=[api_key_output]\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\"):\n",
        "            with gr.Row():\n",
        "                get_data_btn = gr.Button(\"–ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ\", variant=\"primary\")\n",
        "                create_db_btn = gr.Button(\"–°–æ–∑–¥–∞—Ç—å –±–∞–∑—É\", variant=\"secondary\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    gr.Markdown(\"### –î–∞—Ç–∞—Ñ—Ä–µ–π–º\")\n",
        "                    download_btn = gr.Button(\"–°–∫–∞—á–∞—Ç—å –¥–∞—Ç–∞—Ñ—Ä–µ–π–º\")\n",
        "                    download_file = gr.File(label=\"–°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª\", visible=False)\n",
        "                    upload_df = gr.File(label=\"–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Ñ—Ä–µ–π–º (.csv)\", file_types=[\".csv\"])\n",
        "                    load_df_btn = gr.Button(\"–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Ñ—Ä–µ–π–º\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    gr.Markdown(\"### –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞\")\n",
        "                    save_db_btn = gr.Button(\"–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –±–∞–∑—É\")\n",
        "                    upload_db = gr.File(label=\"–ó–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑—É (–ø–∞–ø–∫–∞)\", file_count=\"directory\")\n",
        "                    load_db_btn = gr.Button(\"–ó–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑—É\")\n",
        "\n",
        "            status_output = gr.Textbox(label=\"–°—Ç–∞—Ç—É—Å –æ–ø–µ—Ä–∞—Ü–∏–∏\", interactive=False)\n",
        "            logs_output = gr.Textbox(\n",
        "                label=\"–õ–æ–≥–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\",\n",
        "                lines=10,\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "            # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–±—ã—Ç–∏–π\n",
        "            get_data_btn.click(\n",
        "                assistant.get_data,\n",
        "                outputs=[status_output, logs_output]\n",
        "            )\n",
        "\n",
        "            def handle_download(assistant_ref):\n",
        "                status, filepath = assistant_ref.download_dataframe()\n",
        "                if filepath:\n",
        "                    return status, gr.update(value=filepath, visible=True)\n",
        "                return status, gr.update(visible=False)\n",
        "\n",
        "            download_btn.click(\n",
        "                lambda: handle_download(assistant),\n",
        "                outputs=[status_output, download_file]\n",
        "            )\n",
        "\n",
        "            load_df_btn.click(\n",
        "                lambda file: assistant.load_dataframe(file.name if file else \"\"),\n",
        "                inputs=[upload_df],\n",
        "                outputs=[status_output]\n",
        "            )\n",
        "\n",
        "            create_db_btn.click(\n",
        "                assistant.create_vectorstore,\n",
        "                outputs=[status_output, logs_output]\n",
        "            )\n",
        "\n",
        "            save_db_btn.click(\n",
        "                assistant.save_vectorstore,\n",
        "                outputs=[status_output]\n",
        "            )\n",
        "\n",
        "            load_db_btn.click(\n",
        "                lambda file: assistant.load_vectorstore(file.name if file else \"\"),\n",
        "                inputs=[upload_db],\n",
        "                outputs=[status_output]\n",
        "            )\n",
        "\n",
        "\n",
        "        with gr.Tab(\"üîç –ü–æ–∏—Å–∫\"):\n",
        "            question_input = gr.Textbox(\n",
        "                label=\"–í–∞—à –≤–æ–ø—Ä–æ—Å\",\n",
        "                placeholder=\"–ù–∞–ø—Ä–∏–º–µ—Ä: –ù–∞–π–¥–∏ –Ω–æ—É—Ç–±—É–∫–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥–∞–Ω–Ω—ã—Ö\",\n",
        "                lines=2\n",
        "            )\n",
        "            search_btn = gr.Button(\"–ù–∞–π—Ç–∏\", variant=\"primary\")\n",
        "\n",
        "            answer_output = gr.Textbox(\n",
        "                label=\"–û—Ç–≤–µ—Ç\",\n",
        "                lines=10,\n",
        "                interactive=False\n",
        "            )\n",
        "            tokens_output = gr.Textbox(label=\"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤\", interactive=False)\n",
        "            search_logs_output = gr.Textbox(\n",
        "                label=\"–õ–æ–≥–∏ –ø–æ–∏—Å–∫–∞\",\n",
        "                lines=5,\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "            search_btn.click(\n",
        "                assistant.query_assistant,\n",
        "                inputs=[question_input],\n",
        "                outputs=[answer_output, tokens_output, search_logs_output]\n",
        "            )\n",
        "\n",
        "    return interface\n",
        "\n",
        "# –ó–ê–ü–£–°–ö –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞\n",
        "    interface = create_interface()\n",
        "    interface.launch(\n",
        "        share=True,\n",
        "        debug=True,\n",
        "        server_name=\"0.0.0.0\",\n",
        "        server_port=7860\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNHV9aH8qx+G5BXkyOkiFbM"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}